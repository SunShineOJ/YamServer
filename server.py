# server_enhanced.py
import os
import io
import logging
import sqlite3
from datetime import datetime, timedelta
import subprocess
import tempfile
from typing import List, Dict, Any
import asyncio
from apscheduler.schedulers.background import BackgroundScheduler

import numpy as np
import uvicorn
from fastapi import FastAPI, UploadFile, File, Form, HTTPException
from fastapi.responses import JSONResponse
from fastapi.middleware.cors import CORSMiddleware

# ML
import tensorflow as tf
import tensorflow_hub as hub
import pandas as pd
import librosa
import soundfile as sf
import imageio_ffmpeg as iio_ffmpeg
import noisereduce as nr
import scipy.signal as signal

import time
from datetime import datetime, timedelta

import pytz  # –£—Å—Ç–∞–Ω–æ–≤–∏: pip install pytz

# –£—Å—Ç–∞–Ω–æ–≤–∏ –Ω—É–∂–Ω—ã–π —á–∞—Å–æ–≤–æ–π –ø–æ—è—Å
SERVER_TIMEZONE = pytz.timezone('Europe/Moscow')  # –ò–ª–∏ 'UTC' –µ—Å–ª–∏ —Ö–æ—á–µ—à—å —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–æ

def get_current_datetime():
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–µ–∫—É—â–µ–µ –≤—Ä–µ–º—è –≤ –≤—ã–±—Ä–∞–Ω–Ω–æ–º —á–∞—Å–æ–≤–æ–º –ø–æ—è—Å–µ"""
    return datetime.now(SERVER_TIMEZONE).strftime("%Y-%m-%d %H:%M:%S")

def get_current_date():
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–µ–∫—É—â—É—é –¥–∞—Ç—É –≤ –≤—ã–±—Ä–∞–Ω–Ω–æ–º —á–∞—Å–æ–≤–æ–º –ø–æ—è—Å–µ"""
    return datetime.now(SERVER_TIMEZONE).strftime("%Y-%m-%d")

# ---- Logging ----
logger = logging.getLogger("cough_server_enhanced")
logger.setLevel(logging.INFO)
ch = logging.StreamHandler()
formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
ch.setFormatter(formatter)
logger.addHandler(ch)

# ---- Configuration ----
UPLOAD_FOLDER = "uploads"
DEBUG_FOLDER = "debug_wavs"
DB_PATH = "cough_db.db"
CLEANUP_INTERVAL_HOURS = 1  # –ê–≤—Ç–æ–æ—á–∏—Å—Ç–∫–∞ –∫–∞–∂–¥—ã–µ 1 —á–∞—Å
KEEP_COUGH_FILES_DAYS = 7   # –•—Ä–∞–Ω–∏—Ç—å —Ñ–∞–π–ª—ã —Å –∫–∞—à–ª–µ–º 7 –¥–Ω–µ–π
KEEP_OTHER_FILES_HOURS = 24 # –•—Ä–∞–Ω–∏—Ç—å –æ—Å—Ç–∞–ª—å–Ω—ã–µ —Ñ–∞–π–ª—ã 24 —á–∞—Å–∞

os.makedirs(UPLOAD_FOLDER, exist_ok=True)
os.makedirs(DEBUG_FOLDER, exist_ok=True)

# ---- FastAPI ----
app = FastAPI(title="Enhanced Cough Detection Server")
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"], 
    allow_credentials=True, 
    allow_methods=["*"], 
    allow_headers=["*"]
)

# ---- Database ----
def init_db():
    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS cough_records (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            device_id TEXT,
            filename TEXT,
            file_path TEXT,
            probability REAL,
            cough_detected INTEGER,
            message TEXT,
            top_classes TEXT,
            cough_stats TEXT,
            timestamp DATETIME DEFAULT CURRENT_TIMESTAMP
        )
    ''')
    conn.commit()
    conn.close()
    logger.info("‚úÖ Database initialized")

init_db()

# ---- YAMNet ----
YAMNET_MODEL = None
CLASS_NAMES: List[str] = []
YAMNET_LOADED = False

def load_yamnet():
    global YAMNET_MODEL, CLASS_NAMES, YAMNET_LOADED
    try:
        logger.info("üîÑ Loading YAMNet...")
        YAMNET_MODEL = hub.load('https://tfhub.dev/google/yamnet/1')
        class_map_path = tf.keras.utils.get_file(
            'yamnet_class_map.csv',
            'https://raw.githubusercontent.com/tensorflow/models/master/research/audioset/yamnet/yamnet_class_map.csv'
        )
        CLASS_NAMES = pd.read_csv(class_map_path)['display_name'].tolist()
        YAMNET_LOADED = True
        logger.info(f"‚úÖ YAMNet loaded with {len(CLASS_NAMES)} classes")
    except Exception as e:
        YAMNET_LOADED = False
        logger.exception("‚ùå Failed to load YAMNet: %s", e)

load_yamnet()

def find_cough_indices() -> List[int]:
    return [i for i, n in enumerate(CLASS_NAMES) if 'cough' in n.lower()]

# ---- Audio Processing ----
def decode_android_audio(audio_bytes: bytes, original_filename: str):
    """–†–ê–î–ò–ö–ê–õ–¨–ù–û–ï —Ä–µ—à–µ–Ω–∏–µ - –æ–±—Ö–æ–¥ –±–∏—Ç—ã—Ö WAV –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤"""
    
    file_ext = original_filename.lower().split('.')[-1] if '.' in original_filename else ''
    
    # –ï—Å–ª–∏ —ç—Ç–æ WAV —Ñ–∞–π–ª, –ø—Ä–æ–±—É–µ–º –†–ê–î–ò–ö–ê–õ–¨–ù–´–ï –º–µ—Ç–æ–¥—ã
    if file_ext == 'wav':
        logger.info("üîÑ Detected WAV file, using radical decoding methods...")
        
        try:
            # –ú–ï–¢–û–î 1: –ü—ã—Ç–∞–µ–º—Å—è –ø—Ä–æ—á–∏—Ç–∞—Ç—å –∫–∞–∫ —Å—ã—Ä—ã–µ PCM –¥–∞–Ω–Ω—ã–µ
            # –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã: 16kHz, 16-bit, mono
            try:
                # –ü—Ä–æ–±—É–µ–º –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä–æ–≤–∞—Ç—å –∫–∞–∫ PCM 16-bit
                y = np.frombuffer(audio_bytes[44:], dtype=np.int16).astype(np.float32) / 32768.0
                if len(y) > 1000:  # –ï—Å–ª–∏ –ø–æ–ª—É—á–∏–ª–∏ —Ä–∞–∑—É–º–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ samples
                    logger.info("‚úÖ Success with raw PCM decoding")
                    return {'audio': y, 'sr': 16000, 'method': 'raw_pcm'}
            except:
                pass
            
            # –ú–ï–¢–û–î 2: –ü—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ –Ω–∞—á–∞–ª–æ –∞—É–¥–∏–æ–¥–∞–Ω–Ω—ã—Ö (–ø—Ä–æ–ø—É—Å–∫–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫)
            try:
                # –ò—â–µ–º –¥–∞–Ω–Ω—ã–µ –ø–æ—Å–ª–µ 'data' chunk (–æ–±—ã—á–Ω–æ 44 –±–∞–π—Ç–∞)
                data_start = audio_bytes.find(b'data')
                if data_start != -1:
                    audio_data = audio_bytes[data_start + 8:]  # +8 —á—Ç–æ–±—ã –ø—Ä–æ–ø—É—Å—Ç–∏—Ç—å 'data' –∏ —Ä–∞–∑–º–µ—Ä
                    y = np.frombuffer(audio_data, dtype=np.int16).astype(np.float32) / 32768.0
                    if len(y) > 1000:
                        logger.info("‚úÖ Success with data chunk decoding")
                        return {'audio': y, 'sr': 16000, 'method': 'data_chunk'}
            except:
                pass
            
            # –ú–ï–¢–û–î 3: –ü—Ä–æ–±—É–µ–º –∑–∞–≥—Ä—É–∑–∏—Ç—å –∫–∞–∫ —Å—ã—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ –±–µ–∑ –∑–∞–≥–æ–ª–æ–≤–∫–∞
            try:
                # –ü—Ä–æ—Å—Ç–æ –±–µ—Ä–µ–º –≤—Å–µ –¥–∞–Ω–Ω—ã–µ –∫–∞–∫ PCM
                y = np.frombuffer(audio_bytes, dtype=np.int16).astype(np.float32) / 32768.0
                # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ —Ä–∞–∑—É–º–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è (–∏–∑–±–µ–≥–∞–µ–º —à—É–º)
                y = y[np.abs(y) < 1.0]  # —É–±–∏—Ä–∞–µ–º –≤—ã–±—Ä–æ—Å—ã
                if len(y) > 48000:  # 3 —Å–µ–∫—É–Ω–¥—ã –ø—Ä–∏ 16kHz
                    y = y[:48000]  # –æ–±—Ä–µ–∑–∞–µ–º –¥–æ 3 —Å–µ–∫—É–Ω–¥
                    logger.info("‚úÖ Success with full buffer decoding")
                    return {'audio': y, 'sr': 16000, 'method': 'full_buffer'}
            except:
                pass
                
        except Exception as e:
            logger.warning(f"All radical WAV methods failed: {e}")
    
    # –ï—Å–ª–∏ WAV –º–µ—Ç–æ–¥—ã –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª–∏ –∏–ª–∏ —ç—Ç–æ –Ω–µ WAV, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞—Ä—É—é –ª–æ–≥–∏–∫—É
    logger.info("üîÑ Falling back to standard decoding...")
    with tempfile.NamedTemporaryFile(delete=False, suffix=f'.{file_ext}') as tmp_input:
        tmp_input.write(audio_bytes)
        tmp_input.flush()
        
        results = []
        
        # –ú–µ—Ç–æ–¥ 1: –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π FFmpeg
        try:
            result1 = decode_with_ffmpeg_standard(tmp_input.name)
            results.append(('standard_ffmpeg', result1))
        except Exception as e:
            logger.debug(f"Standard FFmpeg failed: {e}")
        
        # –ú–µ—Ç–æ–¥ 2: FFmpeg –¥–ª—è AMR
        try:
            result2 = decode_with_ffmpeg_amr(tmp_input.name)
            results.append(('amr_ffmpeg', result2))
        except Exception as e:
            logger.debug(f"AMR FFmpeg failed: {e}")
        
        # –ú–µ—Ç–æ–¥ 3: FFmpeg –¥–ª—è AAC/MP4
        try:
            result3 = decode_with_ffmpeg_aac(tmp_input.name)
            results.append(('aac_ffmpeg', result3))
        except Exception as e:
            logger.debug(f"AAC FFmpeg failed: {e}")
        
        if results:
            best_result = select_best_decoding(results)
            os.unlink(tmp_input.name)
            return best_result
        else:
            os.unlink(tmp_input.name)
            raise ValueError("All decoding methods failed")

def decode_with_ffmpeg_standard(input_path: str):
    """–°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ FFmpeg"""
    output_path = tempfile.NamedTemporaryFile(delete=False, suffix='.wav').name
    
    command = [
        'ffmpeg', '-i', input_path,
        '-ac', '1', '-ar', '16000',
        '-acodec', 'pcm_s16le',
        '-y', output_path
    ]
    
    subprocess.run(command, check=True, capture_output=True)
    
    y, sr = librosa.load(output_path, sr=16000)
    os.unlink(output_path)
    
    return {'audio': y, 'sr': sr, 'method': 'standard'}

def decode_with_ffmpeg_amr(input_path: str):
    """–°–ø–µ—Ü–∏–∞–ª—å–Ω–æ–µ –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è AMR-NB"""
    output_path = tempfile.NamedTemporaryFile(delete=False, suffix='.wav').name
    
    command = [
        'ffmpeg', '-i', input_path,
        '-ac', '1', '-ar', '16000',
        '-acodec', 'pcm_s16le',
        '-af', 'highpass=f=80,lowpass=f=3500',
        '-y', output_path
    ]
    
    subprocess.run(command, check=True, capture_output=True)
    
    y, sr = librosa.load(output_path, sr=16000)
    os.unlink(output_path)
    
    return {'audio': y, 'sr': sr, 'method': 'amr_optimized'}

def decode_with_ffmpeg_aac(input_path: str):
    """–°–ø–µ—Ü–∏–∞–ª—å–Ω–æ–µ –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è AAC/MP4"""
    output_path = tempfile.NamedTemporaryFile(delete=False, suffix='.wav').name
    
    command = [
        'ffmpeg', '-i', input_path,
        '-ac', '1', '-ar', '16000', 
        '-acodec', 'pcm_s16le',
        '-af', 'volume=2.0,highpass=f=100',
        '-y', output_path
    ]
    
    subprocess.run(command, check=True, capture_output=True)
    
    y, sr = librosa.load(output_path, sr=16000)
    os.unlink(output_path)
    
    return {'audio': y, 'sr': sr, 'method': 'aac_optimized'}

def select_best_decoding(results):
    """–í—ã–±–∏—Ä–∞–µ—Ç –ª—É—á—à–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è"""
    if not results:
        raise ValueError("All decoding methods failed")
    
    best_result = None
    best_score = -1
    
    for method_name, result in results:
        if result is None:
            continue
            
        y = result['audio']
        score = evaluate_audio_quality(y)
        
        logger.debug(f"Decoding {method_name}: score={score:.3f}")
        
        if score > best_score:
            best_score = score
            best_result = result
    
    logger.info(f"Selected decoding method: {best_result['method']} (score: {best_score:.3f})")
    return best_result

def evaluate_audio_quality(y):
    """–û—Ü–µ–Ω–∏–≤–∞–µ—Ç –∫–∞—á–µ—Å—Ç–≤–æ –∞—É–¥–∏–æ —Å–∏–≥–Ω–∞–ª–∞"""
    if len(y) == 0:
        return 0
    
    # –£—Ä–æ–≤–µ–Ω—å —Å–∏–≥–Ω–∞–ª–∞
    max_amplitude = np.max(np.abs(y))
    if max_amplitude < 0.01:
        level_score = 0
    elif max_amplitude > 0.95:
        level_score = 0.5
    else:
        level_score = min(max_amplitude * 2, 1.0)
    
    # –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–π –¥–∏–∞–ø–∞–∑–æ–Ω
    dynamic_range = np.max(y) - np.min(y)
    dynamic_score = min(dynamic_range * 3, 1.0)
    
    # –≠–Ω–µ—Ä–≥–∏—è –≤ —Ä–µ—á–µ–≤–æ–º –¥–∏–∞–ø–∞–∑–æ–Ω–µ
    sos = signal.butter(4, [80, 4000], 'bandpass', fs=16000, output='sos')
    filtered = signal.sosfilt(sos, y)
    speech_energy = np.mean(filtered ** 2)
    speech_score = min(speech_energy * 100, 1.0)
    
    total_score = level_score * 0.4 + dynamic_score * 0.3 + speech_score * 0.3
    return total_score

def enhanced_audio_processing(y, sr):
    """–£–ª—É—á—à–µ–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∞—É–¥–∏–æ –¥–ª—è Android –∑–∞–ø–∏—Å–µ–π"""
    
    # 1. –®—É–º–æ–ø–æ–¥–∞–≤–ª–µ–Ω–∏–µ
    try:
        noise_sample = y[:min(16000, len(y)//4)]
        y_denoised = nr.reduce_noise(y=y, sr=sr, y_noise=noise_sample, prop_decrease=0.8, stationary=True)
    except:
        y_denoised = y
    
    # 2. –ê–≥—Ä–µ—Å—Å–∏–≤–Ω–æ–µ —É—Å–∏–ª–µ–Ω–∏–µ –¥–ª—è —Ç–∏—Ö–∏—Ö –∑–∞–ø–∏—Å–µ–π
    current_max = np.max(np.abs(y_denoised))
    if current_max < 0.1:
        gain = 10.0
    elif current_max < 0.3:
        gain = 5.0
    else:
        gain = 2.0
    
    y_amplified = y_denoised * gain
    
    # 3. –ö–æ–º–ø—Ä–µ—Å—Å–∏—è
    threshold = 0.3
    ratio = 4
    y_compressed = np.where(np.abs(y_amplified) > threshold, 
                           threshold + (y_amplified - threshold) / ratio, 
                           y_amplified)
    
    # 4. –ü–æ–ª–æ—Å–æ–≤–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –¥–ª—è –∫–∞—à–ª—è
    sos_low = signal.butter(4, 100, 'high', fs=sr, output='sos')
    sos_high = signal.butter(4, 4000, 'low', fs=sr, output='sos')
    
    y_filtered = signal.sosfilt(sos_low, y_compressed)
    y_filtered = signal.sosfilt(sos_high, y_filtered)
    
    # 5. –§–∏–Ω–∞–ª—å–Ω–∞—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
    max_amp = np.max(np.abs(y_filtered))
    if max_amp > 0:
        y_final = y_filtered / max_amp * 0.9
    else:
        y_final = y_filtered
    
    return y_final

# ---- Enhanced Analysis ----
def run_yamnet(waveform: np.ndarray):
    waveform_tf = tf.convert_to_tensor(waveform, dtype=tf.float32)
    scores, embeddings, spectrogram = YAMNET_MODEL(waveform_tf)
    return scores.numpy(), embeddings.numpy(), spectrogram.numpy()

def aggressive_cough_detector_enhanced(y, sr, scores, filename):
    """–£–õ–£–ß–®–ï–ù–ù–´–ô –∞–≥—Ä–µ—Å—Å–∏–≤–Ω—ã–π –¥–µ—Ç–µ–∫—Ç–æ—Ä –∫–∞—à–ª—è –¥–ª—è Android –∑–∞–ø–∏—Å–µ–π"""
    
    cough_idxs = find_cough_indices()
    
    if not cough_idxs:
        return 0.0, False, "No cough classes in YAMNet"
    
    cough_scores = scores[:, cough_idxs]
    per_frame_cough = np.max(cough_scores, axis=1)
    
    # –ë–ê–ó–û–í–´–ï –ú–ï–¢–†–ò–ö–ò YAMNet
    max_prob = np.max(per_frame_cough)
    mean_prob = np.mean(per_frame_cough)
    
    # Android-specific: –±–æ–ª–µ–µ –∞–≥—Ä–µ—Å—Å–∏–≤–Ω—ã–µ –ø–æ—Ä–æ–≥–∏
    very_weak_frames = np.sum(per_frame_cough > 0.005)
    weak_frames = np.sum(per_frame_cough > 0.01)
    medium_frames = np.sum(per_frame_cough > 0.03)
    strong_frames = np.sum(per_frame_cough > 0.08)
    
    total_frames = len(per_frame_cough)
    
    # –ê–ù–ê–õ–ò–ó –≠–ù–ï–†–ì–ï–¢–ò–ß–ï–°–ö–ò–• –ü–ê–¢–¢–ï–†–ù–û–í
    energy_features = analyze_energy_patterns(y, sr)
    
    # –ê–ì–†–ï–°–°–ò–í–ù–ê–Ø –õ–û–ì–ò–ö–ê –î–õ–Ø ANDROID
    detection_reasons = []
    base_prob = 0.0
    
    # –û—Å–Ω–æ–≤–Ω—ã–µ –∫—Ä–∏—Ç–µ—Ä–∏–∏
    if strong_frames >= 1:
        base_prob += 0.5
        detection_reasons.append(f"strong({strong_frames})")
    elif medium_frames >= 2:
        base_prob += 0.4
        detection_reasons.append(f"medium({medium_frames})")
    elif weak_frames >= 3:
        base_prob += 0.3
        detection_reasons.append(f"weak({weak_frames})")
    elif very_weak_frames >= 5:
        base_prob += 0.2
        detection_reasons.append(f"vweak({very_weak_frames})")
    
    # –ë–æ–Ω—É—Å –∑–∞ —ç–Ω–µ—Ä–≥–µ—Ç–∏—á–µ—Å–∫–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
    if energy_features['valid_cough_like_events'] >= 1:
        base_prob += 0.2
        detection_reasons.append(f"energy_events({energy_features['valid_cough_like_events']})")
    
    # –ë–æ–Ω—É—Å –∑–∞ –º–∞–∫—Å–∏–º–∞–ª—å–Ω—É—é –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å
    if max_prob > 0.05:
        base_prob += max_prob
        detection_reasons.append(f"maxP({max_prob:.3f})")
    
    final_prob = min(base_prob, 0.95)
    
    # –û–ß–ï–ù–¨ –ê–ì–†–ï–°–°–ò–í–ù–û–ï –†–ï–®–ï–ù–ò–ï –î–õ–Ø ANDROID
    cough_detected = (
        strong_frames >= 1 or
        medium_frames >= 2 or 
        weak_frames >= 3 or
        (very_weak_frames >= 4 and energy_features['valid_cough_like_events'] >= 1) or
        final_prob > 0.25
    )
    
    reason = " + ".join(detection_reasons) if detection_reasons else "marginal_signals"
    
    logger.info(f"Enhanced detection: {filename} - prob: {final_prob:.3f}, detected: {cough_detected}, reason: {reason}")
    
    return final_prob, cough_detected, reason

def analyze_energy_patterns(y, sr):
    """–ê–Ω–∞–ª–∏–∑ —ç–Ω–µ—Ä–≥–µ—Ç–∏—á–µ—Å–∫–∏—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–Ω—ã—Ö –¥–ª—è –∫–∞—à–ª—è"""
    frame_len = int(0.02 * sr)
    hop_len = frame_len // 2
    
    energies = []
    for i in range(0, len(y) - frame_len, hop_len):
        frame = y[i:i + frame_len]
        energies.append(np.sqrt(np.mean(frame**2)))
    
    energies = np.array(energies)
    
    # –ò—â–µ–º —Ä–µ–∑–∫–∏–µ –∫–æ—Ä–æ—Ç–∫–∏–µ –≤—Å–ø–ª–µ—Å–∫–∏
    threshold = np.percentile(energies, 80)
    spikes = energies > threshold
    
    # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º —Å–º–µ–∂–Ω—ã–µ –≤—Å–ø–ª–µ—Å–∫–∏
    cough_like_events = 0
    in_event = False
    event_start = 0
    
    for i, is_spike in enumerate(spikes):
        if is_spike and not in_event:
            in_event = True
            event_start = i
        elif not is_spike and in_event:
            in_event = False
            event_duration = (i - event_start) * (hop_len / sr)
            if 0.05 < event_duration < 1.0:
                cough_like_events += 1
    
    return {
        'valid_cough_like_events': cough_like_events,
        'total_spikes': np.sum(spikes),
        'max_energy': np.max(energies)
    }

def analyze_audio_enhanced(audio_bytes: bytes, filename: str) -> Dict[str, Any]:
    """–£–õ–£–ß–®–ï–ù–ù–´–ô –∞–Ω–∞–ª–∏–∑ –∞—É–¥–∏–æ —Å –≥–∏–±—Ä–∏–¥–Ω—ã–º –ø–æ–¥—Ö–æ–¥–æ–º"""
    try:
        # –£–ª—É—á—à–µ–Ω–Ω–æ–µ –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ
        decoding_result = decode_android_audio(audio_bytes, filename)
        y = decoding_result['audio']
        sr = decoding_result['sr']
        
        logger.info(f"Decoded: {len(y)} samples, SR: {sr}, method: {decoding_result['method']}")
        
        # –£–ª—É—á—à–µ–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞
        y_processed = enhanced_audio_processing(y, sr)
        
        # –ê–Ω–∞–ª–∏–∑ YAMNet
        scores, _, _ = run_yamnet(y_processed)
        
        # –¢–æ–ø –∫–ª–∞—Å—Å—ã
        mean_scores = np.mean(scores, axis=0)
        top5_idx = np.argsort(mean_scores)[-5:][::-1]
        top5 = [(CLASS_NAMES[i], float(mean_scores[i])) for i in top5_idx]
        
        # –£–ª—É—á—à–µ–Ω–Ω—ã–π –¥–µ—Ç–µ–∫—Ç–æ—Ä –∫–∞—à–ª—è
        final_prob, detected, reason = aggressive_cough_detector_enhanced(y_processed, sr, scores, filename)
        
        # –î–µ—Ç–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        cough_idxs = find_cough_indices()
        cough_stats = {}
        if cough_idxs:
            cough_scores = scores[:, cough_idxs]
            per_frame = np.max(cough_scores, axis=1)
            cough_stats = {
                "max_cough": float(np.max(per_frame)),
                "mean_cough": float(np.mean(per_frame)),
                "cough_frames": int(np.sum(per_frame > 0.05)),
                "total_frames": len(per_frame)
            }
        
        result = {
            "probability": round(final_prob, 3),
            "cough_detected": detected,
            "message": f"Enhanced detection: {reason}",
            "top_classes": top5,
            "cough_stats": cough_stats,
            "decoding_method": decoding_result['method'],
            "processing_applied": True
        }
        
        return convert_numpy_types(result)
        
    except Exception as e:
        logger.error(f"Enhanced analysis failed: {e}")
        # Fallback –Ω–∞ –±–∞–∑–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑
        return analyze_audio_fallback(audio_bytes)

def analyze_audio_fallback(audio_bytes: bytes) -> Dict[str, Any]:
    """–ë–∞–∑–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑ –∫–∞–∫ fallback"""
    wav_path = None
    try:
        wav_path = convert_to_wav_ffmpeg(audio_bytes)
        y, sr = sf.read(wav_path, dtype='float32')
        
        # –ë–∞–∑–æ–≤–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞
        if sr != 16000:
            y = librosa.resample(y, orig_sr=sr, target_sr=16000)
        if y.ndim > 1:
            y = np.mean(y, axis=1)
        max_abs = np.max(np.abs(y))
        if max_abs > 1.0:
            y = y / max_abs
        
        scores, _, _ = run_yamnet(y)
        mean_scores = np.mean(scores, axis=0)
        
        cough_idxs = find_cough_indices()
        cough_prob = np.max(mean_scores[cough_idxs]) if cough_idxs else 0.0
        
        return {
            "probability": round(float(cough_prob), 3),
            "cough_detected": cough_prob > 0.1,
            "message": "Fallback analysis",
            "top_classes": [],
            "cough_stats": {},
            "processing_applied": False
        }
        
    except Exception as e:
        logger.error(f"Fallback analysis also failed: {e}")
        return {
            "probability": 0.0,
            "cough_detected": False,
            "message": f"Analysis failed: {str(e)}",
            "top_classes": [],
            "cough_stats": {},
            "processing_applied": False
        }
    finally:
        if wav_path and os.path.exists(wav_path):
            os.unlink(wav_path)

def convert_to_wav_ffmpeg(audio_bytes: bytes) -> str:
    """–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ WAV —á–µ—Ä–µ–∑ FFmpeg"""
    tmp_in = tempfile.NamedTemporaryFile(delete=False, suffix=".tmp")
    tmp_in.write(audio_bytes)
    tmp_in.close()
    tmp_out = tempfile.NamedTemporaryFile(delete=False, suffix=".wav")
    tmp_out.close()
    ffmpeg_path = iio_ffmpeg.get_ffmpeg_exe()
    try:
        subprocess.run([ffmpeg_path, "-y", "-i", tmp_in.name, "-ar", "16000", "-ac", "1", tmp_out.name],
                       check=True, capture_output=True)
        return tmp_out.name
    except subprocess.CalledProcessError as e:
        logger.error(f"FFmpeg error: {e.stderr.decode()}")
        raise
    finally:
        os.unlink(tmp_in.name)

def convert_numpy_types(obj):
    """–†–µ–∫—É—Ä—Å–∏–≤–Ω–æ –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç numpy —Ç–∏–ø—ã –≤ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ Python —Ç–∏–ø—ã"""
    if isinstance(obj, dict):
        return {key: convert_numpy_types(value) for key, value in obj.items()}
    elif isinstance(obj, list):
        return [convert_numpy_types(item) for item in obj]
    elif isinstance(obj, tuple):
        return tuple(convert_numpy_types(item) for item in obj)
    elif isinstance(obj, (np.int32, np.int64)):
        return int(obj)
    elif isinstance(obj, (np.float32, np.float64)):
        return float(obj)
    elif isinstance(obj, np.bool_):
        return bool(obj)
    elif isinstance(obj, np.ndarray):
        return convert_numpy_types(obj.tolist())
    else:
        return obj

# ---- Auto Cleanup ----
def cleanup_old_files():
    """–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –æ—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö —Ñ–∞–π–ª–æ–≤"""
    try:
        conn = sqlite3.connect(DB_PATH)
        cursor = conn.cursor()
        
        # –ù–∞—Ö–æ–¥–∏–º —Ñ–∞–π–ª—ã –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è
        cutoff_cough = datetime.now() - timedelta(days=KEEP_COUGH_FILES_DAYS)
        cutoff_other = datetime.now() - timedelta(hours=KEEP_OTHER_FILES_HOURS)
        
        # –§–∞–π–ª—ã —Å –∫–∞—à–ª–µ–º —Å—Ç–∞—Ä—à–µ KEEP_COUGH_FILES_DAYS
        cursor.execute('''
            SELECT file_path FROM cough_records 
            WHERE cough_detected=1 AND timestamp < ?
        ''', (cutoff_cough.strftime('%Y-%m-%d %H:%M:%S'),))
        cough_files = [row[0] for row in cursor.fetchall()]
        
        # –û—Å—Ç–∞–ª—å–Ω—ã–µ —Ñ–∞–π–ª—ã —Å—Ç–∞—Ä—à–µ KEEP_OTHER_FILES_HOURS
        cursor.execute('''
            SELECT file_path FROM cough_records 
            WHERE cough_detected=0 AND timestamp < ?
        ''', (cutoff_other.strftime('%Y-%m-%d %H:%M:%S'),))
        other_files = [row[0] for row in cursor.fetchall()]
        
        files_to_delete = cough_files + other_files
        
        # –£–¥–∞–ª—è–µ–º —Ñ–∞–π–ª—ã
        deleted_count = 0
        for file_path in files_to_delete:
            try:
                if os.path.exists(file_path):
                    os.remove(file_path)
                    deleted_count += 1
            except Exception as e:
                logger.warning(f"Could not delete file {file_path}: {e}")
        
        # –£–¥–∞–ª—è–µ–º –∑–∞–ø–∏—Å–∏ –∏–∑ –±–∞–∑—ã
        cursor.execute('''
            DELETE FROM cough_records 
            WHERE cough_detected=1 AND timestamp < ?
        ''', (cutoff_cough.strftime('%Y-%m-%d %H:%M:%S'),))
        
        cursor.execute('''
            DELETE FROM cough_records 
            WHERE cough_detected=0 AND timestamp < ?
        ''', (cutoff_other.strftime('%Y-%m-%d %H:%M:%S'),))
        
        conn.commit()
        conn.close()
        
        logger.info(f"üßπ Cleanup completed: deleted {deleted_count} files and {len(files_to_delete)} database records")
        
    except Exception as e:
        logger.error(f"Cleanup error: {e}")

def start_cleanup_scheduler():
    """–ó–∞–ø—É—Å–∫–∞–µ—Ç –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫ –∞–≤—Ç–æ–æ—á–∏—Å—Ç–∫–∏"""
    scheduler = BackgroundScheduler()
    scheduler.add_job(cleanup_old_files, 'interval', hours=CLEANUP_INTERVAL_HOURS)
    scheduler.start()
    logger.info(f"‚úÖ Auto-cleanup scheduler started (every {CLEANUP_INTERVAL_HOURS} hours)")

# ---- API Endpoints ----
@app.post("/upload")
async def upload_audio(audio: UploadFile = File(...), device_id: str = Form("unknown")):
    logger.info(f"üì• Received upload: {audio.filename}, device_id: {device_id}")
    
    try:
        raw = await audio.read()
        if len(raw) == 0:
            raise HTTPException(status_code=400, detail="Empty file")
        
        # –ò–°–ü–û–õ–¨–ó–£–ï–ú –ï–î–ò–ù–û–ï –í–†–ï–ú–Ø –°–ï–†–í–ï–†–ê
        current_datetime = get_current_datetime()
        current_date = get_current_date()
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"{timestamp}_{device_id}_{audio.filename}"
        path = os.path.join(UPLOAD_FOLDER, filename)
        
        with open(path, "wb") as f: 
            f.write(raw)
        logger.info(f"üíæ Saved raw file: {path} –≤ {current_datetime}")
        
        # –£–õ–£–ß–®–ï–ù–ù–´–ô –∞–Ω–∞–ª–∏–∑
        result = analyze_audio_enhanced(raw, audio.filename)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –±–∞–∑—É —Å –ï–î–ò–ù–´–ú –í–†–ï–ú–ï–ù–ï–ú
        conn = sqlite3.connect(DB_PATH)
        cursor = conn.cursor()
        cursor.execute('''
            INSERT INTO cough_records (device_id, filename, file_path, probability, cough_detected, message, top_classes, cough_stats, timestamp)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
        ''', (
            device_id, filename, path, 
            float(result.get("probability", 0.0)),
            int(bool(result.get("cough_detected"))),
            result.get("message", ""),
            str(result.get("top_classes", [])),
            str(result.get("cough_stats", {})),
            current_datetime  # –Ø–í–ù–û –£–ö–ê–ó–´–í–ê–ï–ú –í–†–ï–ú–Ø –°–ï–†–í–ï–†–ê
        ))
        conn.commit()
        conn.close()
        
        logger.info(f"‚úÖ Analysis result: {result}")
        return JSONResponse({"status": "success", **result})
        
    except Exception as e:
        logger.error(f"Upload error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/stats/{device_id}")
async def get_stats(device_id: str):
    try:
        conn = sqlite3.connect(DB_PATH)
        cursor = conn.cursor()
        
        # –ò–°–ü–û–õ–¨–ó–£–ï–ú –ï–î–ò–ù–£–Æ –î–ê–¢–£ –°–ï–†–í–ï–†–ê
        today = get_current_date()
        logger.info(f"üìä –ó–∞–ø—Ä–æ—Å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –¥–ª—è device_id: {device_id}, –¥–∞—Ç–∞: {today}")
        
        # –û—Å–Ω–æ–≤–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∑–∞ —Å–µ–≥–æ–¥–Ω—è
        cursor.execute('''
            SELECT COUNT(*), 
                   SUM(CASE WHEN cough_detected=1 THEN 1 ELSE 0 END),
                   AVG(CASE WHEN cough_detected=1 THEN probability ELSE NULL END)
            FROM cough_records 
            WHERE device_id=? AND DATE(timestamp)=?
        ''', (device_id, today))
        
        stats = cursor.fetchone()
        total = int(stats[0] or 0) if stats else 0
        total_coughs = int(stats[1] or 0) if stats else 0
        avg_prob = float(stats[2] or 0.0) if stats and stats[2] is not None else 0.0
        
        logger.info(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å–µ–≥–æ–¥–Ω—è: total={total}, coughs={total_coughs}, avg_prob={avg_prob}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –≤–æ–æ–±—â–µ –µ—Å—Ç—å –≤ –±–∞–∑–µ
        cursor.execute('SELECT COUNT(*) FROM cough_records WHERE device_id=?', (device_id,))
        total_device_records = cursor.fetchone()[0] or 0
        logger.info(f"üìä –í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π –¥–ª—è —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞ {device_id}: {total_device_records}")
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —á–∞—Å–∞–º
        cursor.execute('''
            SELECT strftime('%H', timestamp) as hr, COUNT(*) 
            FROM cough_records
            WHERE device_id=? AND cough_detected=1 AND DATE(timestamp)=?
            GROUP BY hr
        ''', (device_id, today))
        rows = cursor.fetchall()
        hourly = [{"hour": f"{h}:00", "count": c} for h, c in rows]
        
        # –ó–∞–ø–æ–ª–Ω—è–µ–º –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ —á–∞—Å—ã –Ω—É–ª—è–º–∏
        for hh in range(24):
            hs = f"{hh:02d}:00"
            if not any(item["hour"] == hs for item in hourly):
                hourly.append({"hour": hs, "count": 0})
        hourly.sort(key=lambda x: x["hour"])
        
        # –ü–æ—Å–ª–µ–¥–Ω–∏–µ —Å–ª—É—á–∞–∏ –∫–∞—à–ª—è
        cursor.execute('''
            SELECT timestamp, probability FROM cough_records
            WHERE device_id=? AND cough_detected=1
            ORDER BY timestamp DESC LIMIT 10
        ''', (device_id,))
        recent_coughs = [{"time": row[0], "probability": float(row[1])} for row in cursor.fetchall()]
        
        # –ê–Ω–∞–ª–∏–∑ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
        peak_hours = "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö"
        cough_frequency = "0 —Ä–∞–∑/–¥–µ–Ω—å"
        intensity = "–ù–∏–∑–∫–∞—è"
        trend = "üìä"
        
        if total_coughs > 0:
            # –ù–∞—Ö–æ–¥–∏–º –ø–∏–∫–æ–≤—ã–µ —á–∞—Å—ã
            if hourly:
                max_hour = max(hourly, key=lambda x: x["count"])
                peak_hours = f"{max_hour['hour']} ({max_hour['count']} —Ä–∞–∑)"
            
            # –ß–∞—Å—Ç–æ—Ç–∞ –∫–∞—à–ª—è
            cough_frequency = f"{total_coughs} —Ä–∞–∑/–¥–µ–Ω—å"
            
            # –ò–Ω—Ç–µ–Ω—Å–∏–≤–Ω–æ—Å—Ç—å
            if avg_prob > 0.7:
                intensity = "–í—ã—Å–æ–∫–∞—è"
            elif avg_prob > 0.3:
                intensity = "–°—Ä–µ–¥–Ω—è—è"
            else:
                intensity = "–ù–∏–∑–∫–∞—è"
            
            # –¢—Ä–µ–Ω–¥ (–ø—Ä–æ—Å—Ç–∞—è –ª–æ–≥–∏–∫–∞)
            cursor.execute('''
                SELECT COUNT(*) FROM cough_records 
                WHERE device_id=? AND cough_detected=1 AND DATE(timestamp)=DATE('now', '-1 day')
            ''', (device_id,))
            yesterday_coughs = cursor.fetchone()[0] or 0
            
            if total_coughs > yesterday_coughs:
                trend = "üìà –†–∞—Å—Ç–µ—Ç"
            elif total_coughs < yesterday_coughs:
                trend = "üìâ –°–Ω–∏–∂–∞–µ—Ç—Å—è"
            else:
                trend = "‚û°Ô∏è –°—Ç–∞–±–∏–ª—å–Ω–æ"
        
        conn.close()
        
        result = {
            "today_stats": {
                "total_recordings": total,
                "total_coughs": total_coughs,
                "avg_probability": round(avg_prob, 3),
                "intensity": intensity
            },
            "hourly_stats": hourly,
            "recent_coughs": recent_coughs,
            "patterns": {
                "peak_hours": peak_hours,
                "cough_frequency": cough_frequency,
                "intensity": intensity,
                "trend": trend
            }
        }
        
        logger.info(f"üìä –§–∏–Ω–∞–ª—å–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏: {result}")
        return result
        
    except Exception as e:
        logger.exception(f"Stats error: {e}")
        return JSONResponse({"status": "error", "message": str(e)})

@app.get("/health")
async def health_check():
    """Health check endpoint"""
    return {
        "status": "healthy",
        "yamnet_loaded": YAMNET_LOADED,
        "timestamp": datetime.now().isoformat(),
        "upload_folder_size": sum(os.path.getsize(os.path.join(UPLOAD_FOLDER, f)) for f in os.listdir(UPLOAD_FOLDER) if os.path.isfile(os.path.join(UPLOAD_FOLDER, f)))
    }

@app.post("/cleanup")
async def manual_cleanup():
    """–†—É—á–Ω–æ–π –∑–∞–ø—É—Å–∫ –æ—á–∏—Å—Ç–∫–∏"""
    cleanup_old_files()
    return {"status": "cleanup completed"}

# ---- Startup ----
@app.on_event("startup")
async def startup_event():
    """–ó–∞–ø—É—Å–∫–∞–µ—Ç—Å—è –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ —Å–µ—Ä–≤–µ—Ä–∞"""
    logger.info("üöÄ Starting Enhanced Cough Detection Server")
    start_cleanup_scheduler()
    # –°—Ä–∞–∑—É –∑–∞–ø—É—Å–∫–∞–µ–º –æ—á–∏—Å—Ç–∫—É –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ
    cleanup_old_files()

# –î–æ–±–∞–≤—å —ç—Ç–∏ endpoint'—ã –ø–æ—Å–ª–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö

@app.get("/debug/db")
async def debug_db():
    """–û—Ç–ª–∞–¥–æ—á–Ω—ã–π endpoint –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö"""
    try:
        conn = sqlite3.connect(DB_PATH)
        cursor = conn.cursor()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤—Å–µ –∑–∞–ø–∏—Å–∏
        cursor.execute('SELECT COUNT(*) as total, SUM(cough_detected) as coughs FROM cough_records')
        stats = cursor.fetchone()
        
        # –ü–æ—Å–ª–µ–¥–Ω–∏–µ 5 –∑–∞–ø–∏—Å–µ–π
        cursor.execute('''
            SELECT device_id, filename, probability, cough_detected, timestamp 
            FROM cough_records 
            ORDER BY timestamp DESC LIMIT 5
        ''')
        recent = cursor.fetchall()
        
        conn.close()
        
        return {
            "total_records": stats[0] or 0,
            "cough_records": stats[1] or 0,
            "recent_entries": [
                {
                    "device_id": row[0],
                    "filename": row[1], 
                    "probability": row[2],
                    "cough_detected": bool(row[3]),
                    "timestamp": row[4]
                } for row in recent
            ]
        }
        
    except Exception as e:
        return {"error": str(e)}

@app.get("/debug/stats/{device_id}")
async def debug_stats(device_id: str):
    """–û—Ç–ª–∞–¥–æ—á–Ω–∞—è –≤–µ—Ä—Å–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ —Å –ø–æ–¥—Ä–æ–±–Ω—ã–º–∏ –ª–æ–≥–∞–º–∏"""
    try:
        conn = sqlite3.connect(DB_PATH)
        cursor = conn.cursor()
        today = datetime.now().strftime("%Y-%m-%d")
        
        logger.info(f"üîç DEBUG STATS: device_id={device_id}, today={today}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∫–∏–µ –∑–∞–ø–∏—Å–∏ –µ—Å—Ç—å –≤ –±–∞–∑–µ –¥–ª—è —ç—Ç–æ–≥–æ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞
        cursor.execute('''
            SELECT COUNT(*), device_id, DATE(timestamp) 
            FROM cough_records 
            WHERE device_id=? 
            GROUP BY device_id, DATE(timestamp)
        ''', (device_id,))
        device_stats = cursor.fetchall()
        
        logger.info(f"üîç DEBUG: –ó–∞–ø–∏—Å–∏ –¥–ª—è —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞ {device_id}: {device_stats}")
        
        # –û—Å–Ω–æ–≤–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∑–∞ —Å–µ–≥–æ–¥–Ω—è - –ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ô –ó–ê–ü–†–û–°
        cursor.execute('''
            SELECT COUNT(*), 
                   SUM(CASE WHEN cough_detected=1 THEN 1 ELSE 0 END),
                   AVG(CASE WHEN cough_detected=1 THEN probability ELSE NULL END)
            FROM cough_records 
            WHERE device_id=? AND DATE(timestamp)=?
        ''', (device_id, today))
        
        stats = cursor.fetchone()
        total = int(stats[0] or 0) if stats else 0
        total_coughs = int(stats[1] or 0) if stats else 0
        avg_prob = float(stats[2] or 0.0) if stats and stats[2] is not None else 0.0
        
        logger.info(f"üîç DEBUG: –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å–µ–≥–æ–¥–Ω—è - total: {total}, coughs: {total_coughs}, avg_prob: {avg_prob}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤—Å–µ –∑–∞–ø–∏—Å–∏ –∑–∞ —Å–µ–≥–æ–¥–Ω—è
        cursor.execute('''
            SELECT filename, cough_detected, probability, timestamp 
            FROM cough_records 
            WHERE device_id=? AND DATE(timestamp)=?
            ORDER BY timestamp DESC
        ''', (device_id, today))
        today_records = cursor.fetchall()
        
        logger.info(f"üîç DEBUG: –ó–∞–ø–∏—Å–∏ –∑–∞ —Å–µ–≥–æ–¥–Ω—è: {len(today_records)}")
        for record in today_records:
            logger.info(f"üîç DEBUG: {record}")
        
        # –û—Å—Ç–∞–ª—å–Ω–æ–π –∫–æ–¥ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏...
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —á–∞—Å–∞–º
        cursor.execute('''
            SELECT strftime('%H', timestamp) as hr, COUNT(*) 
            FROM cough_records
            WHERE device_id=? AND cough_detected=1 AND DATE(timestamp)=?
            GROUP BY hr
        ''', (device_id, today))
        rows = cursor.fetchall()
        hourly = [{"hour": f"{h}:00", "count": c} for h, c in rows]
        
        # –ó–∞–ø–æ–ª–Ω—è–µ–º –≤—Å–µ —á–∞—Å—ã
        for hh in range(24):
            hs = f"{hh:02d}:00"
            if not any(item["hour"] == hs for item in hourly):
                hourly.append({"hour": hs, "count": 0})
        hourly.sort(key=lambda x: x["hour"])
        
        # –ü–æ—Å–ª–µ–¥–Ω–∏–µ —Å–ª—É—á–∞–∏ –∫–∞—à–ª—è
        cursor.execute('''
            SELECT timestamp, probability FROM cough_records
            WHERE device_id=? AND cough_detected=1
            ORDER BY timestamp DESC LIMIT 10
        ''', (device_id,))
        recent_coughs = [{"time": row[0], "probability": float(row[1])} for row in cursor.fetchall()]
        
        conn.close()
        
        result = {
            "today_stats": {
                "total_recordings": total,
                "total_coughs": total_coughs,
                "avg_probability": round(avg_prob, 3)
            },
            "hourly_stats": hourly,
            "recent_coughs": recent_coughs,
            "patterns": {
                "peak_hours": "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö" if total_coughs == 0 else f"{hourly[0]['hour']} ({max([h['count'] for h in hourly])} —Ä–∞–∑)",
                "cough_frequency": f"{total_coughs} —Ä–∞–∑/–¥–µ–Ω—å",
                "intensity": "–í—ã—Å–æ–∫–∞—è" if avg_prob > 0.7 else "–°—Ä–µ–¥–Ω—è—è" if avg_prob > 0.3 else "–ù–∏–∑–∫–∞—è",
                "trend": "üìä"
            },
            "debug_info": {
                "device_id": device_id,
                "today": today,
                "today_records_count": len(today_records),
                "all_records_for_device": device_stats
            }
        }
        
        logger.info(f"üîç DEBUG: –§–∏–Ω–∞–ª—å–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç: {result}")
        return result
        
    except Exception as e:
        logger.exception(f"DEBUG Stats error: {e}")
        return JSONResponse({"status": "error", "message": str(e)})

@app.get("/debug/time")
async def debug_time():
    """–ü–æ–∫–∞–∑–∞—Ç—å —Ç–µ–∫—É—â–µ–µ –≤—Ä–µ–º—è —Å–µ—Ä–≤–µ—Ä–∞"""
    return {
        "server_time": get_current_datetime(),
        "server_date": get_current_date(),
        "timezone": "Europe/Moscow"  # –∏–ª–∏ —Ç–æ—Ç —á—Ç–æ –∏—Å–ø–æ–ª—å–∑—É–µ—à—å
    }

if __name__ == "__main__":
    # –ü–æ–ª—É—á–∞–µ–º –ø–æ—Ä—Ç –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –æ–∫—Ä—É–∂–µ–Ω–∏—è (Railway —Å–∞–º –Ω–∞–∑–Ω–∞—á–∞–µ—Ç)
    port = int(os.environ.get("PORT", 8000))
    logger.info(f"üöÄ Starting enhanced server on 0.0.0.0:{port}, YAMNet loaded: {YAMNET_LOADED}")
    uvicorn.run(app, host="0.0.0.0", port=port, log_level="info")